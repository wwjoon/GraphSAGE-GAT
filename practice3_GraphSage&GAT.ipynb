{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wwjoon/GraphSAGE-GAT/blob/master/practice3_GraphSage%26GAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# **AAI0026 Practice 3: GraphSage and GAT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "In Practice 2, we constructed GNN models by using PyTorch Geometric built in GCN layer, the `GCNConv`. In this Colab we will implement the **GraphSAGE** ([Hamilton et al. (2017)](https://arxiv.org/abs/1706.02216)) and **GAT** ([Veličković et al. (2018)](https://arxiv.org/abs/1710.10903)) layers directly. Then we will run our models on the CORA dataset, which is a standard citation network benchmark dataset.\n",
        "\n",
        "\n",
        "**Note**: Make sure to **sequentially run all the cells in each section**, so that the intermediate variables / packages will carry over to the next cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSaetj53YnT6"
      },
      "source": [
        "# Device\n",
        "You might need to use GPU for this Colab.\n",
        "\n",
        "Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67gOQITlCNQi"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_m9l6OYCQZP",
        "outputId": "c1ca33e1-0915-4a7b-9741-48fa5a311f32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 13.9 MB/s \n",
            "\u001b[?25h  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 467 kB 14.8 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install -q torch-geometric\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PRfgbfTjCRD_",
        "outputId": "f9dcc732-1223-430e-9836-b6feb54a6f43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch_geometric\n",
        "torch_geometric.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoXlf4MtYrbz"
      },
      "source": [
        "# 1 GNN Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQy2RBfgYut4"
      },
      "source": [
        "## Implementing Layer Modules\n",
        "\n",
        "In colab 2, we implemented a network using GCN in node and graph classification tasks. However, the GCN module we used in colab 2 is from the official library. For this problem, we will provide you with a general Graph Neural Network Stack, where you'll be able to plugin your own modules of GraphSAGE and GATs. We will use our implementations to complete node classification on CORA, which is a standard citation network benchmark dataset. In this dataset, nodes correspond to documents and edges correspond to undirected citations. Each node has a class label. The node features are elements of a bag-or-words representation of a document. For the Cora dataset, there are 2708 nodes, 5429 edges, 7 prediction classes for nodes, and 1433 features per node. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4ne6Gw-CT5G"
      },
      "source": [
        "## GNN Stack Module\n",
        "\n",
        "Below is the implementation for a general GNN Module that could plugin any layers, including **GraphSage**, **GAT**, etc. This module is provided for you, and your own **GraphSage** and **GAT** layers will function as components in the GNNStack Module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ys8vZAFPCWWe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch_scatter\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "from torch import Tensor\n",
        "from typing import Union, Tuple, Optional\n",
        "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType,\n",
        "                                    OptTensor)\n",
        "\n",
        "from torch.nn import Parameter, Linear\n",
        "from torch_sparse import SparseTensor, set_diag\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "# https://greeksharifa.github.io/pytorch/2021/09/04/MP/\n",
        "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
        "\n",
        "class GNNStack(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, args, emb=False):\n",
        "        super(GNNStack, self).__init__()\n",
        "        conv_model = self.build_conv_model(args.model_type)\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
        "        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n",
        "        for l in range(args.num_layers-1):\n",
        "            self.convs.append(conv_model(args.heads * hidden_dim, hidden_dim))\n",
        "\n",
        "        # post-message-passing\n",
        "        self.post_mp = nn.Sequential(\n",
        "            nn.Linear(args.heads * hidden_dim, hidden_dim), nn.Dropout(args.dropout), \n",
        "            nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "        self.dropout = args.dropout\n",
        "        self.num_layers = args.num_layers\n",
        "\n",
        "        self.emb = emb\n",
        "\n",
        "    def build_conv_model(self, model_type):\n",
        "        if model_type == 'GraphSage':\n",
        "            return GraphSage\n",
        "        elif model_type == 'GAT':\n",
        "            # When applying GAT with num heads > 1, one needs to modify the \n",
        "            # input and output dimension of the conv layers (self.convs),\n",
        "            # to ensure that the input dim of the next layer is num heads\n",
        "            # multiplied by the output dim of the previous layer.\n",
        "            # HINT: In case you want to play with multiheads, you need to change the for-loop when builds up self.convs to be\n",
        "            # self.convs.append(conv_model(hidden_dim * num_heads, hidden_dim)), \n",
        "            # and also the first nn.Linear(hidden_dim * num_heads, hidden_dim) in post-message-passing.\n",
        "            return GAT\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "          \n",
        "        for i in range(self.num_layers):\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout)\n",
        "\n",
        "        x = self.post_mp(x)\n",
        "\n",
        "        if self.emb == True:\n",
        "            return x\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def loss(self, pred, label):\n",
        "        return F.nll_loss(pred, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syDtxjxoCZgq"
      },
      "source": [
        "## GraphSage Implementation\n",
        "\n",
        "Now let's start working on our own implementation of layers! This part is to get you familiar with how to implement Pytorch layer based on Message Passing. You will be implementing the **forward**, **message** and **aggregate** functions.\n",
        "\n",
        "Generally, the **forward** function is where the actual message passing is conducted. All logic in each iteration happens in **forward**, where we'll call **propagate** function to propagate information from neighbor nodes to central nodes.  So the general paradigm will be pre-processing -> propagate -> post-processing.\n",
        "\n",
        "Recall the process of message passing we introduced. **propagate** further calls **message** which transforms information of neighbor nodes into messages, **aggregate** which aggregates all messages from neighbor nodes into one, and **update** which further generates the embedding for nodes in the next iteration.\n",
        "\n",
        "Our implementation is slightly variant from this, where we'll not explicitly implement **update**, but put the logic for updating nodes in **forward** function. To be more specific, after information is propagated, we can further conduct some operations on the output of **propagate**. The output of **forward** is exactly the embeddings after the current iteration.\n",
        "\n",
        "In addition, tensors passed to **propagate()** can be mapped to the respective nodes $i$ and $j$ by appending _i or _j to the variable name, .e.g. x_i and x_j. Note that we generally refer to $i$ as the central nodes that aggregates information, and refer to $j$ as the neighboring nodes, since this is the most common notation.\n",
        "\n",
        "Please find more details in the comments. One thing to note is that we're adding **skip connections** to our GraphSage. Formally, the update rule for our model is described as below:\n",
        "\n",
        "\\begin{equation}\n",
        "h_v^{(l)} = W_l\\cdot h_v^{(l-1)} + W_r \\cdot AGG(\\{h_u^{(l-1)}, \\forall u \\in N(v) \\})\n",
        "\\end{equation}\n",
        "\n",
        "For simplicity, we use mean aggregations where:\n",
        "\n",
        "\\begin{equation}\n",
        "AGG(\\{h_u^{(l-1)}, \\forall u \\in N(v) \\}) = \\frac{1}{|N(v)|} \\sum_{u\\in N(v)} h_u^{(l-1)}\n",
        "\\end{equation}\n",
        "\n",
        "Additionally, $\\ell$-2 normalization is applied after each iteration.\n",
        "\n",
        "In order to complete the work correctly, we have to understand how the different functions interact with each other. In **propagate** we can pass in any parameters we want. For example, we pass in $x$ as an parameter:\n",
        "\n",
        "... = propagate(..., $x$=($x_{central}$, $x_{neighbor}$), ...)\n",
        "\n",
        "Here $x_{central}$ and $x_{neighbor}$ represent the features from **central** nodes and from **neighbor** nodes. If we're using the same representations from central and neighbor, then $x_{central}$ and $x_{neighbor}$ could be identical.\n",
        "\n",
        "Suppose $x_{central}$ and $x_{neighbor}$ are both of shape N * d, where N is number of nodes, and d is dimension of features.\n",
        "\n",
        "Then in message function, we can take parameters called $x\\_i$ and $x\\_j$. Usually $x\\_i$ represents \"central nodes\", and $x\\_j$ represents \"neighbor nodes\". Pay attention to the shape here: $x\\_i$ and $x\\_j$ are both of shape E * d (**not N!**). $x\\_i$ is obtained by concatenating the embeddings of central nodes of all edges through lookups from $x_{central}$ we passed in propagate. Similarly, $x\\_j$ is obtained by concatenating the embeddings of neighbor nodes of all edges through lookups from $x_{neighbor}$ we passed in propagate.\n",
        "\n",
        "Let's look at an example. Suppose we have 4 nodes, so $x_{central}$ and $x_{neighbor}$ are of shape 4 * d. We have two edges (1, 2) and (3, 0). Thus, $x\\_i$ is obtained by $[x_{central}[1]^T; x_{central}[3]^T]^T$, and $x\\_j$ is obtained by $[x_{neighbor}[2]^T; x_{neighbor}[0]^T]^T$\n",
        "\n",
        "<font color='red'>For the following questions, DON'T refer to any existing implementations online.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RwG4HqCFCaOD"
      },
      "outputs": [],
      "source": [
        "class GraphSage(MessagePassing):\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, normalize = True,\n",
        "                 bias = False, **kwargs):  \n",
        "        super(GraphSage, self).__init__(**kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.normalize = normalize\n",
        "\n",
        "        self.lin_l = None\n",
        "        self.lin_r = None\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Define the layers needed for the message and update functions below.\n",
        "        # self.lin_l is the linear transformation that you apply to embedding \n",
        "        #            for central node.\n",
        "        # self.lin_r is the linear transformation that you apply to aggregated \n",
        "        #            message from neighbors.\n",
        "        # Our implementation is ~2 lines, but don't worry if you deviate from this.\n",
        "        self.lin_l = torch.nn.Linear(self.in_channels, self.out_channels)\n",
        "        self.lin_r = torch.nn.Linear(self.in_channels, self.out_channels)\n",
        "        ############################################################################\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin_l.reset_parameters()\n",
        "        self.lin_r.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index, size = None):\n",
        "        \"\"\"\"\"\"\n",
        "\n",
        "        out = None\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement message passing, as well as any post-processing (our update rule).\n",
        "        # 1. First call propagate function to conduct the message passing.\n",
        "        #    1.1 See there for more information: \n",
        "        #        https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
        "        #    1.2 We use the same representations for central (x_central) and \n",
        "        #        neighbor (x_neighbor) nodes, which means you'll pass x=(x, x) \n",
        "        #        to propagate.\n",
        "        # 2. Update our node embedding with skip connection.\n",
        "        # 3. If normalize is set, do L-2 normalization (defined in \n",
        "        #    torch.nn.functional)\n",
        "        # Our implementation is ~5 lines, but don't worry if you deviate from this.\n",
        "        out = self.propagate(edge_index, x=x, size=size)\n",
        "        out = self.lin_r(out)\n",
        "\n",
        "        x = self.lin_l(x)\n",
        "\n",
        "        out = x + out\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j):\n",
        "\n",
        "        out = None\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement your message function here.\n",
        "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
        "        out = x_j\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "    def aggregate(self, inputs, index, dim_size = None):\n",
        "\n",
        "        out = None\n",
        "\n",
        "        # The axis along which to index number of nodes.\n",
        "        node_dim = self.node_dim\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement your aggregate function here.\n",
        "        # See here as how to use torch_scatter.scatter: \n",
        "        # https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html#torch_scatter.scatter\n",
        "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
        "        out = torch_scatter.scatter(inputs, index, node_dim, dim_size=dim_size, reduce='mean')\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qx1bA2m1SWA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjcfF3RACdLD"
      },
      "source": [
        "## GAT Implementation\n",
        "\n",
        "Attention mechanisms have become the state-of-the-art in many sequence-based tasks such as machine translation and learning sentence representations. One of the major benefits of attention-based mechanisms is their ability to focus on the most relevant parts of the input to make decisions. In this problem, we will see how attention mechanisms can be used to perform node classification of graph-structured data through the usage of Graph Attention Networks (GATs).\n",
        "\n",
        "The building block of the Graph Attention Network is the graph attention layer, which is a variant of the aggregation function . Let $N$ be the number of nodes and $F$ be the dimension of the feature vector for each node. The input to each graph attentional layer is a set of node features: $\\mathbf{h} = \\{\\overrightarrow{h_1}, \\overrightarrow{h_2}, \\dots, \\overrightarrow{h_N}$\\}, $\\overrightarrow{h_i} \\in R^F$. The output of each graph attentional layer is a new set of node features, which may have a new dimension $F'$: $\\mathbf{h'} = \\{\\overrightarrow{h_1'}, \\overrightarrow{h_2'}, \\dots, \\overrightarrow{h_N'}\\}$, with $\\overrightarrow{h_i'} \\in \\mathbb{R}^{F'}$.\n",
        "\n",
        "We will now describe this transformation of the input features into higher-level features performed by each graph attention layer. First, a shared linear transformation parametrized by the weight matrix $\\mathbf{W} \\in \\mathbb{R}^{F' \\times F}$ is applied to every node. Next, we perform self-attention on the nodes. We use a shared attentional mechanism:\n",
        "\\begin{equation} \n",
        "a : \\mathbb{R}^{F'} \\times \\mathbb{R}^{F'} \\rightarrow \\mathbb{R}.\n",
        "\\end{equation}\n",
        "\n",
        "This mechanism computes the attention coefficients that capture the importance of node $j$'s features to node $i$:\n",
        "\\begin{equation}\n",
        "e_{ij} = a(\\mathbf{W_l}\\overrightarrow{h_i}, \\mathbf{W_r} \\overrightarrow{h_j})\n",
        "\\end{equation}\n",
        "The most general formulation of self-attention allows every node to attend to all other nodes which drops all structural information. To utilize graph structure in the attention mechanisms, we can use masked attention. In masked attention, we only compute $e_{ij}$ for nodes $j \\in \\mathcal{N}_i$ where $\\mathcal{N}_i$ is some neighborhood of node $i$ in the graph.\n",
        "\n",
        "To easily compare coefficients across different nodes, we normalize the coefficients across $j$ using a softmax function:\n",
        "\\begin{equation}\n",
        "\\alpha_{ij} = \\text{softmax}_j(e_{ij}) = \\frac{\\exp(e_{ij})}{\\sum_{k \\in \\mathcal{N}_i} \\exp(e_{ik})}\n",
        "\\end{equation}\n",
        "\n",
        "For this problem, our attention mechanism $a$ will be a single-layer feedforward neural network parametrized by a weight vector $\\overrightarrow{a} \\in \\mathbb{R}^{F'}$, followed by a LeakyReLU nonlinearity (with negative input slope 0.2). Let $\\cdot^T$ represent transposition and $||$ represent concatenation. The coefficients computed by our attention mechanism may be expressed as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\alpha_{ij} = \\frac{\\exp\\Big(\\text{LeakyReLU}\\Big(\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i} + \\overrightarrow{a_r}^T\\mathbf{W_r}\\overrightarrow{h_j}\\Big)\\Big)}{\\sum_{k\\in \\mathcal{N}_i} \\exp\\Big(\\text{LeakyReLU}\\Big(\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i} + \\overrightarrow{a_r}^T\\mathbf{W_r}\\overrightarrow{h_k}\\Big)\\Big)}\n",
        "\\end{equation}\n",
        "\n",
        "For the following questions, we denote $\\alpha_l = [...,\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i},...]$ and $\\alpha_r = [..., \\overrightarrow{a_r}^T \\mathbf{W_r} \\overrightarrow{h_j}, ...]$.\n",
        "\n",
        "\n",
        "At every layer of GAT, after the attention coefficients are computed for that layer, the aggregation function can be computed by a weighted sum of neighborhood messages, where weights are specified by $\\alpha_{ij}$.\n",
        "\n",
        "Now, we use the normalized attention coefficients to compute a linear combination of the features corresponding to them. These aggregated features will serve as the final output features for every node.\n",
        "\n",
        "\\begin{equation}\n",
        "h_i' = \\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij} \\mathbf{W_r} \\overrightarrow{h_j}.\n",
        "\\end{equation}\n",
        "\n",
        "To stabilize the learning process of self-attention, we use multi-head attention. To do this we use $K$ independent attention mechanisms, or ``heads'' compute output features as in the above equations. Then, we concatenate these output feature representations:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\overrightarrow{h_i}' = ||_{k=1}^K \\Big(\\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij}^{(k)} \\mathbf{W_r}^{(k)} \\overrightarrow{h_j}\\Big)\n",
        "\\end{equation}\n",
        "\n",
        "where $||$ is concentation, $\\alpha_{ij}^{(k)}$ are the normalized attention coefficients computed by the $k$-th attention mechanism $(a^k)$, and $\\mathbf{W}^{(k)}$ is the corresponding input linear transformation's weight matrix. Note that for this setting, $\\mathbf{h'} \\in \\mathbb{R}^{KF'}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "w4j45gTpCeXO"
      },
      "outputs": [],
      "source": [
        "class GAT(MessagePassing):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, heads = 2,\n",
        "                 negative_slope = 0.2, dropout = 0., **kwargs):\n",
        "        super(GAT, self).__init__(node_dim=0, **kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.heads = heads\n",
        "        self.negative_slope = negative_slope\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.lin_l = None\n",
        "        self.lin_r = None\n",
        "        self.att_l = None\n",
        "        self.att_r = None\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Define the layers needed for the message functions below.\n",
        "        # self.lin_l is the linear transformation that you apply to embeddings \n",
        "        # BEFORE message passing.\n",
        "        # Pay attention to dimensions of the linear layers, since we're using \n",
        "        # multi-head attention.\n",
        "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
        "        self.lin_l = torch.nn.Linear(self.in_channels, self.heads * self.out_channels)\n",
        "        ############################################################################\n",
        "\n",
        "        self.lin_r = self.lin_l\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Define the attention parameters \\overrightarrow{a_l/r}^T in the above intro.\n",
        "        # You have to deal with multi-head scenarios.\n",
        "        # Use nn.Parameter instead of nn.Linear\n",
        "        # Our implementation is ~2 lines, but don't worry if you deviate from this.\n",
        "        self.att_l = torch.nn.Parameter(torch.Tensor(1, self.heads, self.out_channels))\n",
        "        self.att_r = torch.nn.Parameter(torch.Tensor(1, self.heads, self.out_channels))\n",
        "        ############################################################################\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.lin_l.weight)\n",
        "        nn.init.xavier_uniform_(self.lin_r.weight)\n",
        "        nn.init.xavier_uniform_(self.att_l)\n",
        "        nn.init.xavier_uniform_(self.att_r)\n",
        "\n",
        "    def forward(self, x, edge_index, size = None):\n",
        "        \n",
        "        H, C = self.heads, self.out_channels\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement message passing, as well as any pre- and post-processing (our update rule).\n",
        "        # 1. First apply linear transformation to node embeddings, and split that \n",
        "        #    into multiple heads. We use the same representations for source and\n",
        "        #    target nodes, but apply different linear weights (W_l and W_r)\n",
        "        # 2. Calculate alpha vectors for central nodes (alpha_l) and neighbor nodes (alpha_r).\n",
        "        # 3. Call propagate function to conduct the message passing. \n",
        "        #    3.1 Remember to pass alpha = (alpha_l, alpha_r) as a parameter.\n",
        "        #    3.2 See there for more information: https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
        "        # 4. Transform the output back to the shape of N * d.\n",
        "        # Our implementation is ~5 lines, but don't worry if you deviate from this.\n",
        "\n",
        "        x_l = self.lin_l(x).reshape(-1, H, C)\n",
        "        x_r = self.lin_r(x).reshape(-1, H, C)\n",
        "        # alpha_l = self.att_l * x_l\n",
        "        # alpha_r = self.att_r * x_r\n",
        "        alpha_l = (self.att_l * x_l).sum(dim=-1)\n",
        "        alpha_r = (self.att_r * x_r).sum(dim=-1)\n",
        "        out = self.propagate(edge_index, x=(x_l, x_r), alpha=(alpha_l, alpha_r), size=size)\n",
        "        out = out.reshape(-1, H*C)\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def message(self, x_j, alpha_j, alpha_i, index, ptr, size_i):\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement your message function. Putting the attention in message \n",
        "        # instead of in update is a little tricky.\n",
        "        # 1. Calculate the final attention weights using alpha_i and alpha_j,\n",
        "        #    and apply leaky Relu.\n",
        "        # 2. Calculate softmax over the neighbor nodes for all the nodes. Use \n",
        "        #    torch_geometric.utils.softmax instead of the one in Pytorch.\n",
        "        # 3. Apply dropout to attention weights (alpha).\n",
        "        # 4. Multiply embeddings and attention weights. As a sanity check, the output\n",
        "        #    should be of shape E * H * d.\n",
        "        # 5. ptr (LongTensor, optional): If given, computes the softmax based on\n",
        "        #    sorted inputs in CSR representation. You can simply pass it to softmax.\n",
        "        # Don't worry if you deviate from this.\n",
        "\n",
        "        alpha = F.leaky_relu(alpha_i + alpha_j, negative_slope=self.negative_slope)\n",
        "        if ptr:\n",
        "            att_weight = F.softmax(alpha, ptr)\n",
        "        else:\n",
        "            att_weight = torch_geometric.utils.softmax(alpha, index)\n",
        "        # Fill below with 2 lines \n",
        "        alpha = F.dropout(alpha, p=self.dropout)\n",
        "        out = alpha.unsqueeze(-1) * x_j\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def aggregate(self, inputs, index, dim_size = None):\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here! \n",
        "        # Implement your aggregate function here.\n",
        "        # See here as how to use torch_scatter.scatter: https://pytorch-scatter.readthedocs.io/en/latest/_modules/torch_scatter/scatter.html\n",
        "        # Pay attention to \"reduce\" parameter is different from that in GraphSage.\n",
        "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
        "        \n",
        "        out = torch_scatter.scatter(inputs, index, self.node_dim, dim_size=dim_size, reduce='sum')\n",
        "        ############################################################################\n",
        "    \n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2dkgSuWCheU"
      },
      "source": [
        "## Building Optimizers\n",
        "\n",
        "This function has been implemented for you. **For grading purposes please use the default Adam optimizer**, but feel free to play with other types of optimizers on your own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "f_TIQ8NPCjBP"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def build_optimizer(args, params):\n",
        "    weight_decay = args.weight_decay\n",
        "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
        "    if args.opt == 'adam':\n",
        "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'sgd':\n",
        "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
        "    elif args.opt == 'rmsprop':\n",
        "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'adagrad':\n",
        "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    if args.opt_scheduler == 'none':\n",
        "        return None, optimizer\n",
        "    elif args.opt_scheduler == 'step':\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
        "    elif args.opt_scheduler == 'cos':\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
        "    return scheduler, optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBYdWFwYCkwY"
      },
      "source": [
        "## Training and Testing\n",
        "\n",
        "Here we provide you with the functions to train and test. **Please do not modify this part for grading purposes.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_tZMWRc8CmGg"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def train(dataset, args):\n",
        "    \n",
        "    print(\"Node task. test set size:\", np.sum(dataset[0]['train_mask'].numpy()))\n",
        "    test_loader = loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)\n",
        "\n",
        "    # build model\n",
        "    model = GNNStack(dataset.num_node_features, args.hidden_dim, dataset.num_classes, \n",
        "                            args)\n",
        "    scheduler, opt = build_optimizer(args, model.parameters())\n",
        "\n",
        "    # train\n",
        "    losses = []\n",
        "    test_accs = []\n",
        "    for epoch in range(args.epochs):\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        for batch in loader:\n",
        "            opt.zero_grad()\n",
        "            pred = model(batch)\n",
        "            label = batch.y\n",
        "            pred = pred[batch.train_mask]\n",
        "            label = label[batch.train_mask]\n",
        "            loss = model.loss(pred, label)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total_loss += loss.item() * batch.num_graphs\n",
        "        total_loss /= len(loader.dataset)\n",
        "        losses.append(total_loss)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "          test_acc = test(test_loader, model)\n",
        "          test_accs.append(test_acc)\n",
        "          print(\"Epoch \", epoch, \"Loss: \", total_loss, \"Test Acc.: \", test_acc)\n",
        "        else:\n",
        "          test_accs.append(test_accs[-1])\n",
        "    return test_accs, losses\n",
        "\n",
        "def test(loader, model, is_validation=True):\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        with torch.no_grad():\n",
        "            # max(dim=1) returns values, indices tuple; only need indices\n",
        "            pred = model(data).max(dim=1)[1]\n",
        "            label = data.y\n",
        "\n",
        "        mask = data.val_mask if is_validation else data.test_mask\n",
        "        # node classification: only evaluate on nodes in test set\n",
        "        pred = pred[mask]\n",
        "        label = data.y[mask]\n",
        "            \n",
        "        correct += pred.eq(label).sum().item()\n",
        "\n",
        "    total = 0\n",
        "    for data in loader.dataset:\n",
        "        total += torch.sum(data.val_mask if is_validation else data.test_mask).item()\n",
        "    return correct / total\n",
        "  \n",
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7-h7jIsCns4"
      },
      "source": [
        "## Let's Start the Training!\n",
        "\n",
        "We will be working on the CORA dataset on node-level classification.\n",
        "\n",
        "This part is implemented for you. **For grading purposes, please do not modify the default parameters.** However, feel free to play with different configurations just for fun!\n",
        "\n",
        "**Submit your best accuracy and loss on Gradescope.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qe9B45l9Cpz2",
        "outputId": "925f6244-8716-41dc-853a-0df53331dd46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n",
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node task. test set size: 140\n",
            "Epoch  0 Loss:  1.9642833471298218 Test Acc.:  0.316\n",
            "Epoch  10 Loss:  1.0539777278900146 Test Acc.:  0.472\n",
            "Epoch  20 Loss:  0.4473777413368225 Test Acc.:  0.604\n",
            "Epoch  30 Loss:  0.1700429469347 Test Acc.:  0.666\n",
            "Epoch  40 Loss:  0.1377301961183548 Test Acc.:  0.654\n",
            "Epoch  50 Loss:  0.1442321389913559 Test Acc.:  0.686\n",
            "Epoch  60 Loss:  0.1787964254617691 Test Acc.:  0.678\n",
            "Epoch  70 Loss:  0.1514977365732193 Test Acc.:  0.652\n",
            "Epoch  80 Loss:  0.1309724599123001 Test Acc.:  0.678\n",
            "Epoch  90 Loss:  0.1744164228439331 Test Acc.:  0.702\n",
            "Epoch  100 Loss:  0.12912583351135254 Test Acc.:  0.67\n",
            "Epoch  110 Loss:  0.1123112291097641 Test Acc.:  0.69\n",
            "Epoch  120 Loss:  0.10725697129964828 Test Acc.:  0.656\n",
            "Epoch  130 Loss:  0.14869080483913422 Test Acc.:  0.672\n",
            "Epoch  140 Loss:  0.12336846441030502 Test Acc.:  0.702\n",
            "Epoch  150 Loss:  0.09733490645885468 Test Acc.:  0.65\n",
            "Epoch  160 Loss:  0.10481613129377365 Test Acc.:  0.702\n",
            "Epoch  170 Loss:  0.09444680064916611 Test Acc.:  0.706\n",
            "Epoch  180 Loss:  0.08709899336099625 Test Acc.:  0.696\n",
            "Epoch  190 Loss:  0.14252276718616486 Test Acc.:  0.664\n",
            "Epoch  200 Loss:  0.11760848015546799 Test Acc.:  0.706\n",
            "Epoch  210 Loss:  0.1216588020324707 Test Acc.:  0.694\n",
            "Epoch  220 Loss:  0.08051075041294098 Test Acc.:  0.704\n",
            "Epoch  230 Loss:  0.14115658402442932 Test Acc.:  0.716\n",
            "Epoch  240 Loss:  0.1345752775669098 Test Acc.:  0.688\n",
            "Epoch  250 Loss:  0.190623477101326 Test Acc.:  0.698\n",
            "Epoch  260 Loss:  0.12286864966154099 Test Acc.:  0.708\n",
            "Epoch  270 Loss:  0.09625048190355301 Test Acc.:  0.694\n",
            "Epoch  280 Loss:  0.11264145374298096 Test Acc.:  0.7\n",
            "Epoch  290 Loss:  0.0859442725777626 Test Acc.:  0.666\n",
            "Epoch  300 Loss:  0.11350610107183456 Test Acc.:  0.724\n",
            "Epoch  310 Loss:  0.08905909210443497 Test Acc.:  0.73\n",
            "Epoch  320 Loss:  0.0974520593881607 Test Acc.:  0.694\n",
            "Epoch  330 Loss:  0.12364977598190308 Test Acc.:  0.688\n",
            "Epoch  340 Loss:  0.10522370040416718 Test Acc.:  0.708\n",
            "Epoch  350 Loss:  0.07419342547655106 Test Acc.:  0.686\n",
            "Epoch  360 Loss:  0.09770364314317703 Test Acc.:  0.708\n",
            "Epoch  370 Loss:  0.08866686373949051 Test Acc.:  0.692\n",
            "Epoch  380 Loss:  0.11424542963504791 Test Acc.:  0.712\n",
            "Epoch  390 Loss:  0.06620781868696213 Test Acc.:  0.708\n",
            "Epoch  400 Loss:  0.13019008934497833 Test Acc.:  0.7\n",
            "Epoch  410 Loss:  0.0818067342042923 Test Acc.:  0.696\n",
            "Epoch  420 Loss:  0.08959012478590012 Test Acc.:  0.726\n",
            "Epoch  430 Loss:  0.07464594393968582 Test Acc.:  0.718\n",
            "Epoch  440 Loss:  0.07752454280853271 Test Acc.:  0.726\n",
            "Epoch  450 Loss:  0.0789014995098114 Test Acc.:  0.662\n",
            "Epoch  460 Loss:  0.06913745403289795 Test Acc.:  0.71\n",
            "Epoch  470 Loss:  0.07200256735086441 Test Acc.:  0.718\n",
            "Epoch  480 Loss:  0.05187942087650299 Test Acc.:  0.714\n",
            "Epoch  490 Loss:  0.14513830840587616 Test Acc.:  0.706\n",
            "Maximum accuracy: 0.73\n",
            "Minimum loss: 0.0451979823410511\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# GraphSage\n",
        "\n",
        "def main():\n",
        "    for args in [\n",
        "        {'model_type': 'GraphSage', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
        "         'batch_size': 32, 'hidden_dim': 32, 'dropout': 0.5, 'epochs': 500, \n",
        "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, \n",
        "         'weight_decay': 5e-3, 'lr': 0.01},\n",
        "    ]:\n",
        "        args = objectview(args)\n",
        "        for model in ['GraphSage']:\n",
        "            args.model_type = model\n",
        "\n",
        "            # Match the dimension.\n",
        "            if model == 'GAT':\n",
        "              args.heads = 2\n",
        "            else:\n",
        "              args.heads = 1\n",
        "\n",
        "            if args.dataset == 'cora':\n",
        "                dataset = Planetoid(root='/tmp/cora', name='Cora')\n",
        "            else:\n",
        "                raise NotImplementedError(\"Unknown dataset\") \n",
        "            test_accs, losses = train(dataset, args) \n",
        "\n",
        "            print(\"Maximum accuracy: {0}\".format(max(test_accs)))\n",
        "            print(\"Minimum loss: {0}\".format(min(losses)))\n",
        "\n",
        "            plt.title(dataset.name)\n",
        "            plt.plot(losses, label=\"training loss\" + \" - \" + args.model_type)\n",
        "            plt.plot(test_accs, label=\"test accuracy\" + \" - \" + args.model_type)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1bYmz-q93HLk",
        "outputId": "3b372c28-d3be-4e55-d987-be16634c4a20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node task. test set size: 140\n",
            "Epoch  0 Loss:  1.9480488300323486 Test Acc.:  0.162\n",
            "Epoch  10 Loss:  1.9110037088394165 Test Acc.:  0.232\n",
            "Epoch  20 Loss:  1.934910774230957 Test Acc.:  0.29\n",
            "Epoch  30 Loss:  1.7790775299072266 Test Acc.:  0.28\n",
            "Epoch  40 Loss:  1.7019214630126953 Test Acc.:  0.25\n",
            "Epoch  50 Loss:  1.6715799570083618 Test Acc.:  0.338\n",
            "Epoch  60 Loss:  1.5238267183303833 Test Acc.:  0.36\n",
            "Epoch  70 Loss:  1.4285749197006226 Test Acc.:  0.418\n",
            "Epoch  80 Loss:  1.2497016191482544 Test Acc.:  0.422\n",
            "Epoch  90 Loss:  1.2772102355957031 Test Acc.:  0.41\n",
            "Epoch  100 Loss:  1.1204581260681152 Test Acc.:  0.382\n",
            "Epoch  110 Loss:  1.079702615737915 Test Acc.:  0.386\n",
            "Epoch  120 Loss:  1.0574493408203125 Test Acc.:  0.402\n",
            "Epoch  130 Loss:  1.0319697856903076 Test Acc.:  0.418\n",
            "Epoch  140 Loss:  0.8966916799545288 Test Acc.:  0.406\n",
            "Epoch  150 Loss:  0.856358528137207 Test Acc.:  0.428\n",
            "Epoch  160 Loss:  0.7932919263839722 Test Acc.:  0.464\n",
            "Epoch  170 Loss:  0.8201526403427124 Test Acc.:  0.42\n",
            "Epoch  180 Loss:  0.6910905241966248 Test Acc.:  0.46\n",
            "Epoch  190 Loss:  0.6765552163124084 Test Acc.:  0.474\n",
            "Epoch  200 Loss:  0.6436007022857666 Test Acc.:  0.508\n",
            "Epoch  210 Loss:  0.6048071980476379 Test Acc.:  0.496\n",
            "Epoch  220 Loss:  0.6235406994819641 Test Acc.:  0.48\n",
            "Epoch  230 Loss:  0.5376482009887695 Test Acc.:  0.488\n",
            "Epoch  240 Loss:  0.47898510098457336 Test Acc.:  0.488\n",
            "Epoch  250 Loss:  0.48565417528152466 Test Acc.:  0.508\n",
            "Epoch  260 Loss:  0.39348816871643066 Test Acc.:  0.514\n",
            "Epoch  270 Loss:  0.41197460889816284 Test Acc.:  0.506\n",
            "Epoch  280 Loss:  0.41967687010765076 Test Acc.:  0.518\n",
            "Epoch  290 Loss:  0.3650144636631012 Test Acc.:  0.504\n",
            "Epoch  300 Loss:  0.3596928119659424 Test Acc.:  0.502\n",
            "Epoch  310 Loss:  0.3864811360836029 Test Acc.:  0.5\n",
            "Epoch  320 Loss:  0.32176974415779114 Test Acc.:  0.492\n",
            "Epoch  330 Loss:  0.3407522439956665 Test Acc.:  0.502\n",
            "Epoch  340 Loss:  0.33023062348365784 Test Acc.:  0.512\n",
            "Epoch  350 Loss:  0.33433911204338074 Test Acc.:  0.53\n",
            "Epoch  360 Loss:  0.28769683837890625 Test Acc.:  0.548\n",
            "Epoch  370 Loss:  0.28955724835395813 Test Acc.:  0.54\n",
            "Epoch  380 Loss:  0.2738695740699768 Test Acc.:  0.524\n",
            "Epoch  390 Loss:  0.2624819576740265 Test Acc.:  0.528\n",
            "Epoch  400 Loss:  0.3339616656303406 Test Acc.:  0.548\n",
            "Epoch  410 Loss:  0.2505531311035156 Test Acc.:  0.51\n",
            "Epoch  420 Loss:  0.2572327256202698 Test Acc.:  0.528\n",
            "Epoch  430 Loss:  0.24315716326236725 Test Acc.:  0.502\n",
            "Epoch  440 Loss:  0.36023634672164917 Test Acc.:  0.512\n",
            "Epoch  450 Loss:  0.22781923413276672 Test Acc.:  0.546\n",
            "Epoch  460 Loss:  0.31100285053253174 Test Acc.:  0.55\n",
            "Epoch  470 Loss:  0.26033300161361694 Test Acc.:  0.52\n",
            "Epoch  480 Loss:  0.24679312109947205 Test Acc.:  0.534\n",
            "Epoch  490 Loss:  0.26137182116508484 Test Acc.:  0.536\n",
            "Maximum accuracy: 0.55\n",
            "Minimum loss: 0.22781923413276672\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# GAT\n",
        "def main():\n",
        "    for args in [\n",
        "        {'model_type': 'GraphSage', 'dataset': 'cora', 'num_layers': 2, 'heads': 1, \n",
        "         'batch_size': 32, 'hidden_dim': 32, 'dropout': 0.5, 'epochs': 500, \n",
        "         'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, \n",
        "         'weight_decay': 5e-3, 'lr': 0.001},\n",
        "    ]:\n",
        "        args = objectview(args)\n",
        "        for model in ['GAT']:\n",
        "            args.model_type = model\n",
        "\n",
        "            # Match the dimension.\n",
        "            if model == 'GAT':\n",
        "              args.heads = 2\n",
        "            else:\n",
        "              args.heads = 1\n",
        "\n",
        "            if args.dataset == 'cora':\n",
        "                dataset = Planetoid(root='/tmp/cora', name='Cora')\n",
        "            else:\n",
        "                raise NotImplementedError(\"Unknown dataset\") \n",
        "            test_accs, losses = train(dataset, args) \n",
        "\n",
        "            print(\"Maximum accuracy: {0}\".format(max(test_accs)))\n",
        "            print(\"Minimum loss: {0}\".format(min(losses)))\n",
        "\n",
        "            plt.title(dataset.name)\n",
        "            plt.plot(losses, label=\"training loss\" + \" - \" + args.model_type)\n",
        "            plt.plot(test_accs, label=\"test accuracy\" + \" - \" + args.model_type)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHELqjARZ1W5"
      },
      "source": [
        "## Question 1.1: What is the maximum accuracy you could get on test set for GraphSage?\n",
        "\n",
        "Maximum accuracy:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlCtBEBLMBkR"
      },
      "source": [
        "## Question 1.2: What is the maximum accuracy you could get on test set for GAT?\n",
        "\n",
        "Maximum accuracy:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7JXsMTBgeOI"
      },
      "source": [
        "# Submission\n",
        "\n",
        "In order to get credit, you need to submit the `ipynb` file of Colab 3 to LMS.\n",
        "To get this file, click `File` and `Download .ipynb`. Please make sure that your output of each cell is available in your `ipynb` file."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}